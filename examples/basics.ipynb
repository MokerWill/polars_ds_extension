{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f4422-5c3a-4bd6-abe0-a15edfc62abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ds as pds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a314316",
   "metadata": {},
   "source": [
    "# This notebook illustrates the basic usage of this package\n",
    "\n",
    "You need to create an environment with this package installed to run this notebook. (usually latest version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef5c69-fff3-4779-9b58-f939d725f0b0",
   "metadata": {},
   "source": [
    "# Num Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fec01-5d0b-422f-b099-c86037512b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10_000\n",
    "df = pl.DataFrame({\n",
    "    \"f\": np.sin(list(range(size)))\n",
    "    , \"time_idx\": range(size)\n",
    "    , \"dummy\": [\"a\"] * (size // 2) + [\"b\"] * (size // 2)\n",
    "    , \"actual\": np.round(np.random.random(size=size)).astype(np.int32)\n",
    "    , \"predicted\": np.random.random(size=size)\n",
    "    , \"dummy_groups\":[\"a\"] * (size//2) + [\"b\"] * (size//2) \n",
    "}).with_columns(\n",
    "    pds.random(0., 1.).alias(\"x1\")\n",
    "    , pds.random(0., 1.).alias(\"x2\")\n",
    "    , pds.random(0., 1.).alias(\"x3\")\n",
    "    , pds.random(0., 1.).alias(\"a\")\n",
    "    , pds.random(0., 1.).alias(\"b\")\n",
    ").with_columns(\n",
    "    y = pl.col(\"x1\") * 0.15 + pl.col(\"x2\") * 0.3 - pl.col(\"x3\") * 1.5 + pds.random() * 0.0001,\n",
    "    y2 = pl.col(\"x1\") * 0.13 + pl.col(\"x2\") * 0.45 - pl.col(\"x3\") * 0.1 + pds.random() * 0.0001\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f98453-34cd-4afc-b35d-db58fa60a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-wise Jaccard Similarity. Result should be 0 as they are distinct\n",
    "df.select(\n",
    "    pds.jaccard_col(\"x1\", pl.col(\"x2\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d5346-e75b-4769-a953-e898d6a4d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT. First is real part, second is complex part\n",
    "# By default, this behaves the same as np's rfft, which returns a non-redundant \n",
    "# compact representation of fft output.\n",
    "df.select(\n",
    "    pds.rfft(\"f\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c76353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT. But return the full length\n",
    "df.select(\n",
    "    pds.rfft(\"f\", return_full=True)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6662d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Convolutions at once\n",
    "# Modes: `same`, `left` (left-aligned same), `right` (right-aligned same), `valid` or `full`\n",
    "# Method: `fft`, `direct`\n",
    "# Currently slower than SciPy but provides parallelism because of Polars\n",
    "df.select(\n",
    "    pds.convolve(\"f\", [-1, 0, 0, 0, 1], mode = \"full\", method = \"fft\"), # column f with the kernel given here\n",
    "    pds.convolve(\"a\", [-1, 0, 0, 0, 1], mode = \"full\", method = \"direct\"),\n",
    "    pds.convolve(\"b\", [-1, 0, 0, 0, 1], mode = \"full\", method = \"direct\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47b643-6bcc-43f6-9a25-82168c33e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "df.select(\n",
    "    pds.lin_reg(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = pl.col(\"y\"),\n",
    "        add_bias=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94324b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression, multi-target\n",
    "df.select(\n",
    "    pds.lin_reg(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = [pl.col(\"y\"), pl.col(\"y2\")],\n",
    "        add_bias=False\n",
    "    )\n",
    ").unnest(\"coeffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6da23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pds.lin_reg_report(\n",
    "        # formulaic input is also available for lstsq related queries, \n",
    "        # or you can always use polars expressions, e.g. pl.col('x1') + 1, pl.col('x2').exp(), pl.col('x3').sin()\n",
    "        \"ln(x1+1)\", \"exp(x2)\", \"sin(x3)\",\n",
    "        target = \"y\",\n",
    "        add_bias = True\n",
    "    ).alias(\"report\")\n",
    ").unnest(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16511624-fc7f-45fc-b28e-ad9a91c1bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    \"dummy\",\n",
    "    pds.lin_reg(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = pl.col(\"y\"),\n",
    "        add_bias=False\n",
    "    ).over(pl.col(\"dummy\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want prediction and residue instead of coefficients\n",
    "df.select(\n",
    "    \"x1\",\n",
    "    \"x2\",\n",
    "    \"y\",\n",
    "    pds.lin_reg(\n",
    "        \"x1\", pl.col(\"x2\"),\n",
    "        target = \"y\",\n",
    "        add_bias=False, \n",
    "        return_pred=True\n",
    "    ).alias(\"prediction\")\n",
    ").unnest(\"prediction\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb061-340d-423d-9107-772387006ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy\").agg(\n",
    "    pds.lin_reg(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = pl.col(\"y\"),\n",
    "        add_bias=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "df.group_by(\"dummy\").agg(\n",
    "    pds.lin_reg(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = pl.col(\"y\"),\n",
    "        l1_reg = 0.1,\n",
    "        add_bias=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdae8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 metric of lasso regressions on each group\n",
    "df.group_by(\"dummy\").agg(\n",
    "    pds.query_r2(\n",
    "        actual = pl.col(\"y\"),\n",
    "        pred = pds.lin_reg(\n",
    "            pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "            target = pl.col(\"y\"),\n",
    "            l1_reg = 0.1,\n",
    "            return_pred = True,\n",
    "            add_bias=False\n",
    "        ).struct.field(\"pred\")\n",
    "    ).alias(\"lasso_r2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ff27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling regression\n",
    "df.select(\n",
    "    \"y\",\n",
    "    \"x1\",\n",
    "    \"x2\",\n",
    "    pds.rolling_lin_reg(\n",
    "        \"x1\", \"x2\",\n",
    "        target = \"y\",\n",
    "        window_size = 5,\n",
    "        null_policy = \"zero\"\n",
    "    ).alias(\"result\")\n",
    ").unnest(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fda8ca-57e7-4e02-a3f0-283ecce66a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Entropy, should be 0 because x1 is an ID\n",
    "df.select(\n",
    "    pds.query_cond_entropy(\"y\", \"x1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81def1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only want singular values (principal values?)\n",
    "df.select(\n",
    "    pds.singular_values(\"a\", \"b\", \"x1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc497383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular values + The principal components\n",
    "df.select(\n",
    "    pds.pca(\"a\", \"b\")\n",
    ").unnest(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC1\n",
    "df.select(\n",
    "    pds.principal_components(\"a\", \"b\", k =1).alias(\"principal_components\")\n",
    ").unnest(\"principal_components\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e036f",
   "metadata": {},
   "source": [
    "# ML Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d094-3c4c-4230-a589-1027c5690162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy_groups\").agg(\n",
    "    pds.query_l2(\"actual\", \"predicted\").alias(\"l2\"),\n",
    "    pds.query_log_loss(\"actual\", \"predicted\").alias(\"log loss\"),\n",
    "    pds.query_binary_metrics(actual=\"actual\", pred=\"predicted\").alias(\"combo\")\n",
    ").unnest(\"combo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7c6e3-0f1d-45f0-9fdb-cdb303b98556",
   "metadata": {},
   "source": [
    "# Str Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad36f9-264e-4a49-bf36-936639440edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100_000\n",
    "df2 = pl.DataFrame({\n",
    "    \"sen\":[\"Hello, world! I'm going to church.\"] * size,\n",
    "    \"word\":[\"words\", \"word\"] * (size //2)\n",
    "})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee123a7e-7f9b-4f48-a5d5-6354799201ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "df2.select(\n",
    "    pds.str_tokenize(pl.col(\"sen\").str.to_lowercase()).explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33017e3-17df-498b-93d9-1d656a344388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pds.str_tokenize(pl.col(\"sen\").str.to_lowercase(), stem=True).explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69237c02-5f9f-4e92-b68d-6ac43aad1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pds.str_leven(\"word\", pl.lit(\"world\"))\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damerau-Levenshtein\n",
    "df2.select(\n",
    "    pds.str_d_leven(\"word\", pl.lit(\"world\"))\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795396dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select( # column \"word\" vs. the word \"world\"\n",
    "    pds.str_leven(\"word\", pl.lit(\"world\"), return_sim = True)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad7633-67fa-47f3-b86a-9f4cd097a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(\n",
    "    # This is way faster than computing ditance and then doing a filter\n",
    "    pds.filter_by_levenshtein(pl.col(\"word\"), pl.lit(\"world\"), 1) # <= 1. \n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9477c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"word\":[\"apple\", \"banana\", \"pineapple\", \"asasasas\", \"sasasass\"],\n",
    "    \"other_data\": [1,2,3,4,5]\n",
    "})\n",
    "gibberish = [\"asasasa\", \"sasaaasss\", \"asdasadadfa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    # Nearest string\n",
    "    pds.str_nearest(\"word\", word = \"banana\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    # Filters to words that are similar to any word in vocab\n",
    "    pds.similar_to_vocab(\n",
    "        pl.col(\"word\"),\n",
    "        vocab = gibberish,\n",
    "        threshold = 0.5,\n",
    "        metric = \"lv\", # Levenshtein similarity. Other options: dleven, osa, jw\n",
    "        strategy = \"any\" # True if the word is similar to any word in vocab. Other options: \"all\", \"avg\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pds.str_leven(\"word\", pl.lit(\"asasasa\"), return_sim=True).alias(\"asasasa\"),\n",
    "    pds.str_leven(\"word\", pl.lit(\"sasaaasss\"), return_sim=True).alias(\"sasaaasss\"),\n",
    "    pds.str_leven(\"word\", pl.lit(\"asdasadadfa\"), return_sim=True).alias(\"asdasadadfa\"),\n",
    "    pds.str_fuzz(\"word\", pl.lit(\"apples\")).alias(\"LCS based Fuzz match - apples\"),\n",
    "    pds.str_osa(\"word\", pl.lit(\"apples\"), return_sim=True).alias(\"Optimal String Alignment - apples\"),\n",
    "    pds.str_jw(\"word\", pl.lit(\"apples\")).alias(\"Jaro-Winkler - apples\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841f2a1",
   "metadata": {},
   "source": [
    "# Stats Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"a\": [None, None] + list(np.random.normal(size = 998))\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random numbers, respecting null positions in reference column (pl.col(\"a\"))\n",
    "df.with_columns(\n",
    "    pds.random_normal(mean = 0.5, std = 1.0).alias(\"random_normal\"),\n",
    "    pl.when(pl.col(\"a\").is_null()).then(None).otherwise(\n",
    "        pds.random_normal(mean = 0.5, std = 1.0).alias(\"random_normal\")\n",
    "    ).alias(\"random_normal_that_respects_null_of_a\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e13f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random string\n",
    "df.with_columns(\n",
    "    pds.random_str(min_size = 1, max_size = 5).alias(\"random_str\"),\n",
    "    pl.when(pl.col(\"a\").is_null()).then(None).otherwise(\n",
    "        pds.random_str(min_size = 1, max_size = 5)\n",
    "    ).alias(\"random_str_that_respects_null_of_a\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c37394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate fixed size random string, while respecting column a's nulls\n",
    "df.with_columns(\n",
    "    pl.when(pl.col(\"a\").is_null()).then(None).otherwise(\n",
    "        pds.random_str(min_size = 5, max_size = 5)\n",
    "    ).alias(\"random_str\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    # Sample from a normal distribution, using reference column \"a\" 's mean and std\n",
    "    pds.random_normal(pl.col(\"a\").mean(), pl.col(\"a\").std()).alias(\"test1\") \n",
    "    # Sample from uniform distribution, with low = 0 and high = \"a\"'s max, and respect the nulls in \"a\"\n",
    "    , pl.when(pl.col(\"a\").is_null()).then(None).otherwise(\n",
    "        pds.random(lower = 0., upper = pl.col(\"a\").max()).alias(\"test2\")\n",
    "    )\n",
    ").with_columns(\n",
    "    # Add a random pertubation to test1\n",
    "    pds.perturb(\"test1\", epsilon=0.001).alias(\"test1_perturbed\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New in v0.3.5\n",
    "# This way, we don't have a reference column, so we cannot respect nulls, but is more convenient to use.\n",
    "df.with_columns(\n",
    "    pds.random().alias(\"[0, 1)\"),\n",
    "    pds.random_normal(pl.col(\"a\").mean(), pl.col(\"a\").std()).alias(\"Normal\"),\n",
    "    pds.random_int(0, 10).alias(\"Int from [0, 10)\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate 2 random sample, both normally distributed\n",
    "# Run Welch's t test on them, p value should be big since they have equal mean\n",
    "# Run a normality test. Again, p value should be big since they are normally distributed \n",
    "\n",
    "df.with_columns(\n",
    "    pds.random_normal(0.5, 1.0).alias(\"test1\"),\n",
    "    pds.random_normal(0.5, 2.0).alias(\"test2\"),\n",
    ").select(\n",
    "    pds.ttest_ind(\"test1\", \"test2\", equal_var=False).alias(\"t-test\"),\n",
    "    pds.normal_test(\"test1\").alias(\"normality_test\")\n",
    ").select(\n",
    "    pl.col(\"t-test\").struct.field(\"statistic\").alias(\"t-tests: statistics\")\n",
    "    , pl.col(\"t-test\").struct.field(\"pvalue\").alias(\"t-tests: pvalue\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"statistic\").alias(\"normality_test: statistics\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"pvalue\").alias(\"normality_test: pvalue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5_000\n",
    "df = pl.DataFrame({\n",
    "    \"market_id\": range(size),\n",
    "}).with_columns(\n",
    "    pl.col(\"market_id\").mod(3),\n",
    "    var1 = pds.random(),\n",
    "    var2 = pds.random(),\n",
    "    category_1 = pds.random_int(0, 5),\n",
    "    category_2 = pds.random_int(0, 10),\n",
    ")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In dataframe statistical tests!\n",
    "df.select(\n",
    "    pds.ttest_ind(\"var1\", \"var2\", equal_var=True).alias(\"t-test\"),\n",
    "    pds.chi2(\"category_1\", \"category_2\").alias(\"chi2-test\"),\n",
    "    pds.f_test(\"var1\", group = \"category_1\").alias(\"f-test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also be done in group by context\n",
    "print(\n",
    "    df.group_by(\"market_id\").agg(\n",
    "        pds.ttest_ind(\"var1\", \"var2\", equal_var=False).alias(\"t-test\"),\n",
    "        pds.chi2(\"category_1\", \"category_2\").alias(\"chi2-test\"),\n",
    "        pds.f_test(\"var1\", group = \"category_1\").alias(\"f-test\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benford's law\n",
    "df.select(\n",
    "    first_digit_cnt = pds.query_first_digit_cnt(pl.col(\"var1\")).explode()\n",
    ").with_columns(\n",
    "    # This doesn't follow benford's law because it is random data\n",
    "    first_digit_distribution = pl.col(\"first_digit_cnt\") / pl.col(\"first_digit_cnt\").sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232e4d7",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Related Tasks\n",
    "\n",
    "These queries can be very slow when data/dimension gets huge, even when processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds as pds\n",
    "size = 2000\n",
    "df = pl.DataFrame({\n",
    "    \"id\": range(size), \n",
    "}).with_columns(\n",
    "    pds.random().alias(\"var1\"),\n",
    "    pds.random().alias(\"var2\"),\n",
    "    pds.random().alias(\"var3\"),\n",
    "    pds.random().alias(\"r\"),\n",
    "    (pds.random() * 10).alias(\"rh\"),\n",
    "    pl.col(\"id\").cast(pl.UInt32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neighbor count. The point itself is always considered a neighbor to itself.\n",
    "df.with_columns(\n",
    "    pds.query_nb_cnt(\n",
    "        pl.col(\"var1\"), \"var2\", \"var3\", # Columns used as the coordinates in n-d space, str | pl.Expr \n",
    "        r = 0.1, # radius \n",
    "        dist = \"inf\", # L Infinity distance \n",
    "        parallel = True \n",
    "    ).alias(\"nb_l_inf_cnt\")\n",
    ").head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    pds.query_nb_cnt(\n",
    "        \"var1\", \"var2\", \"var3\", # Columns used as the coordinates in n-d space, str | pl.Expr \n",
    "        r = pl.col(\"r\"), # radius be an expression too\n",
    "        dist = \"l1\", # L 1 distance \n",
    "        parallel = True \n",
    "    ).alias(\"nb_l1_r_cnt\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors. \n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pds.query_knn_ptwise(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in n-d space\n",
    "        index = \"id\",  # pl.col(\"id\"), str | pl.Expr\n",
    "        k = 3, \n",
    "        dist = \"l2\", # squared l2\n",
    "        parallel = True\n",
    "    ).alias(\"best friends\")\n",
    ").head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a769f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all neighbors within radius r, call them best friends\n",
    "print(\n",
    "\n",
    "df.select(\n",
    "    pl.col(\"id\"),\n",
    "    pds.query_radius_ptwise(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in 3d space\n",
    "        index = pl.col(\"id\"),\n",
    "        r = 0.1, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True\n",
    "    ).alias(\"best friends\"),\n",
    ").with_columns( # -1 to remove the point itself\n",
    "    (pl.col(\"best friends\").list.len() - 1).alias(\"best friends count\")\n",
    ").head()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors and distances\n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pds.query_knn_ptwise(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in n-d space\n",
    "        index = pl.col(\"id\"),\n",
    "        k = 3, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True,\n",
    "        return_dist = True\n",
    "    ).alias(\"best_friends_w_dist\")\n",
    ").unnest(\"best_friends_w_dist\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c69ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only points near the given point\n",
    "df.filter(\n",
    "    pds.within_dist_from(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in n-d space\n",
    "        pt = [0.5, 0.5, 0.5],\n",
    "        r = 0.2,\n",
    "        dist = \"l2\" # actually this is squared l2, so this is asking for squared l2 <= 0.2\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine distance is available when dimension is 2\n",
    "df.filter(\n",
    "    pds.within_dist_from(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), # Columns used as the coordinates in n-d space\n",
    "        pt = [0.5, 0.5],\n",
    "        r = 10, # in km\n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pds.within_dist_from(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), \n",
    "        pt = [0.5, 0.5],\n",
    "        # radius can also be an existing column in the dataframe.\n",
    "        r = pl.col(\"rh\"), \n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14627bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = df.select(\n",
    "    pl.col(\"id\").cast(pl.UInt64),\n",
    "    pds.query_radius_ptwise(\n",
    "        # Columns used as the coordinates in n-d space\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), \n",
    "        index=pl.col(\"id\"),\n",
    "        r = 0.02, \n",
    "        dist = \"l2\",\n",
    "    ).alias(\"friends\")\n",
    ").with_columns(\n",
    "    pl.col(\"friends\").list.len().alias(\"count\")\n",
    ")\n",
    "friends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98264a05",
   "metadata": {},
   "source": [
    "# Using PDS Expressions On pl.Series, NumPy arrays, or pd.Series, etc.\n",
    "\n",
    "The output by default is always a Polars Series. The user gets to choose whether to turn it into NumPy, Pandas, or other data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from polars_ds.compat import compat as pds2\n",
    "\n",
    "df = pds.frame(size=100_000).select(\n",
    "    pds.random(0.0, 1.0).round().alias(\"actual\"),\n",
    "    pds.random(0.0, 1.0).alias(\"predicted\"),\n",
    "    pds.random_int(0, 3).alias(\"0-2\"),\n",
    "    pds.random_int(0, 10).alias(\"0-9\"),\n",
    "    pds.random_str(min_size=1, max_size=2).alias(\"s1\"),\n",
    "    pds.random_str(min_size=1, max_size=2).alias(\"s2\"),\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6574a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70830d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series\n",
    "pds2.jaccard_col(df_pd[\"0-2\"], df_pd[\"0-9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars Series\n",
    "print(pds2.query_binary_metrics(df[\"actual\"], df[\"predicted\"]).struct.unnest())\n",
    "# Pyarrow Series\n",
    "print(pds2.query_binary_metrics(df[\"actual\"].to_arrow(), df[\"predicted\"].to_arrow()).struct.unnest())\n",
    "# NumPy\n",
    "print(pds2.query_binary_metrics(df[\"actual\"].to_numpy(), df[\"predicted\"].to_numpy()).struct.unnest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy Arrays\n",
    "pds2.psi(\n",
    "    np.random.random(size = 1000), \n",
    "    np.random.random(size = 1000), \n",
    "    n_bins = 5, \n",
    "    return_report = True\n",
    ").struct.unnest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds2.query_cid_ce(\n",
    "    np.random.random(size = 1000),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c14067",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds2.query_c3_stats(\n",
    "    pl.Series(values=np.random.random(size = 1000)), \n",
    "    lag = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds2.str_leven(df[\"s1\"], df[\"s2\"]).head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aab4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f45764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ds as pds\n",
    "\n",
    "df = pds.frame(size=100_000).select(\n",
    "    pds.random(0.0, 1.0).round().alias(\"actual\"),\n",
    "    pds.random(0.0, 1.0).alias(\"predicted\"),\n",
    "    pds.random_int(0, 3).alias(\"category\"),\n",
    ").with_columns(\n",
    "    (pl.col(\"category\") == 0).alias(\"category\")\n",
    ").with_row_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7806d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ds as pds\n",
    "from polars_ds import transforms as t\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"a\": [float('nan'), None, float(\"inf\"), 9999, 100, 100, 100, 800],\n",
    "})\n",
    "\n",
    "df.with_columns(\n",
    "    t.conditional_impute(\n",
    "        df, \n",
    "        {\"a\": ((pl.col(\"a\").is_finite().not_()) | pl.col(\"a\").is_null() | (pl.col(\"a\") > 899))},\n",
    "        method = \"mean\"\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a962fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.col(\"a\").is_finite().not_() | \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5acf09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
